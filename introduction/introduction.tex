\chapter{Introduction}

The field of \textit{software diversity} is concerned with researching the
causes and effects of diversity in software and software engineering, both in the result
and the process. As an example consider web browsers; There are many different implementations
of what is essentially the same functionality. In the context of security vulnerabilities
of one browser does not necessarily carry over to another\cite{survey}.

One of the applications of software diversity is as a defense to code re-use attacks\cite{survey}.
Code-reuse attacks refers to attacks that diverts program control flow to re-use already
present code in an unintended manner\cite{code-re-use}. For example if an adversary gains
access to a process' stack the address to jump to after a return instruction can be
overwritten and the adversary can choose which instruction to jump to. \textcite{rop}
extended on this concept and introduced what is called \textit{return oriented programming}.
Return oriented programming is a code re-use technique were the program control flow is
diverted to a chain of short instruction sequences, dubbed a \textit{gadget}. By carefully
choosing these gadgets an adversary can achieve arbitrary code execution.

However, the adversary relies on the fact that the chosen instruction sequences are always
equivalent across all binary files. I.e an equivalent sequence of instructions is located
at the exact same offset. If, for example, everyone would run their own, semantically
different but functionally equivalent version of the Firefox web browser an adversary would
have to disassemble all variations and construct a unique payload for every target. Thus,
techniques that provide diversity between executables and/or runtimes have been researched
as a defense to these code re-use attacks\cite{survey}.

Constraint programming is a paradigm for solving combinatorial search problems wherein
the relationship between variables are expressed as \textit{constraints}. It solves problems
such as scheduling, vehicle routing and, in our case, compiling
\cite{handbook-constraint-programming, unison-docs}. For example, consider the problem
of scheduling working shifts in a store. The variables could be the start and end time
of a shift for one person, and the constraint could be that there are always two employees
present in the store and no one works for more than 8 consecutive hours.

A \textit{constraint solver} takes a problem such as the example above and finds a value
for all the variables such that all constraints are satisfied, or in the case when no
mapping that satisfies all constraints exists proves that such is the case
\cite{handbook-constraint-programming}. The process of finding these values consists of
\textit{searching} the combinatorial space and either implicitly or explicitly discarding
combinations that cannot be solutions, i.e does not satisfy the constraints.

\textit{Unison} is a tool that uses a constraint solver to schedule instructions and allocate
registers as a single, integrated problem. It operates as a part of the LLVM backend, and
is thus not a standalone compiler. Unison is potentially optimal in the sense that given
enough time, it can generate the optimal instruction schedule and register allocation.
It finds this solution by searching the combinatorial space in a continuous pursuit for a
solution that is better than the last\cite{unison-docs}.

\section{Problem Statement}

It might feel intuitive to provide software diversity by somehow randomizing a part of an
executable, and in fact many have\cite{survery,librando,binary-stirring}, but this
approach comes with a few problems. When generating the executables you cannot make any
guarantees regarding the resulting population. If you generate two different executable
you cannot with certainty tell that they are not equal. The risk of them being equal is
most likely very small for just two versions, but what if 10000 different version are
generated? Or 1000000? At some point the pigeonhole principle comes into effect, in which
case case it would be better to re-use the already generated code.

By instead systematically generating different variations those sort of guarantees can be
made. If two equal executables are never generated it follows that they are all pairwise
distinct (with respect to our diversification technique). It also follows that if the
code generator is run to termination, all pairwise distinct versions are generated.
The nature of constraint solving lends itself well to this application. This is where
Unison comes in; In addition to its main purpose Unison has potential for software
diversity purposes.

This thesis aims to be an early exploration of a systematic approach to automated software
diversity using a constraint solver, specifically the Unison tool. It aims to evaluate 
both the code generator and the generated code. This leads us to the hypothesis that

\say{Systematically generating diverse executables using a constraint solver is at least
as good as basing the diversification process on randomization.}

\section{Motivation}

In addition to what is mentioned in the problem statement, perhaps the most compelling
reason to use a constraint solver for software diversity is that for a combination to be
considered a solution, \textit{all} constraints must be satisfied.  Regardless of what
unorthodox approach we want to try out we do not need to consider it's effect on program
functionality, since the constraints that ensure a valid program is generated must still
be satisfied. This property makes implementing new techniques relatively simple. Modifying
code while retaining functionality is no easy task, and this simplifies it greatly.

With the systematic approach there is full control of what changes between versions, and
how much it changes between versions. Instead of introducing randomness into some part of
the compilation process and more or less hope it generates diverse code with low overhead
the systematic approach offers the possibility of properly reasoning about the process and
steering it specific manners. It also yields a greater control of the quality of the
generated code. Limits can be dynamically set in place so that it does not exceed e.g a
certain number of instructions.
