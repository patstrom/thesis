\chapter{Introduction}

The field of \textit{software diversity} is concerned with researching the
causes and effects of diversity in software and software engineering, both in the result
and the process. As an example consider web browsers. There are many different implementations
of what is essentially the same functionality. In the context of security vulnerabilities
of one browser does not necessarily carry over to another \cite{survey}.

One of the applications of software diversity is as a defense to code re-use attacks \cite{survey}.
Code-reuse attacks refers to attacks that diverts program control flow to re-use already
present code in an unintended manner \cite{code-re-use}. For example if an adversary gains
access to a process' stack the address to jump to after a return instruction can be
overwritten and the adversary can choose which instruction to jump to. \textcite{rop}
extended this concept and introduced what is called \textit{return-oriented programming}.
Return oriented programming is a code re-use technique were the program control flow is
diverted to a chain of short instruction sequences, dubbed a \textit{gadget}. By carefully
choosing these gadgets an adversary can achieve arbitrary code execution.

However, the adversary relies on the fact that the chosen instruction sequences are always
equivalent across all binary files. In other words an equivalent sequence of instructions
is located at the exact same offset. If, for example, everyone would run their own,
structurally different but functionally equivalent version of the Firefox web browser an
adversary would have to disassemble all variations and construct a unique payload for
every target. Thus, techniques that provide diversity between executables and/or runtimes
have been researched as a defense to these code re-use attacks \cite{survey}.

To understand how two executables can be structurally different but functionally equal
consider an example pertaining the instruction schedule. Say there are two independent
instructions, one of which is part of a gadget. By swapping the place of these two
instructions the gadget is now different, but since the instructions are independent
program functionality is the same. There are many decisions taken by the compiler that are
not necessarily the only valid decision, and if one could explore all combinations of
decisions one could systematically generate the entire population of diversely arranged
but functionally equivalent executables.

Constraint programming is a paradigm for solving combinatorial search problems wherein
the relationship between variables are expressed as \textit{constraints}. It solves problems
such as scheduling, vehicle routing and, in our case, compiling
 \cite{handbook-constraint-programming, unison-docs}. For example, consider the problem
of scheduling working shifts in a store. The variables could be the start and end time
of a shift for one person, and the constraint could be that there are always two employees
present in the store and no one works for more than 8 consecutive hours.

A \textit{constraint solver} takes a problem such as the example above and finds a value
for all the variables such that all constraints are satisfied, or in the case when no
mapping that satisfies all constraints exists proves that such is the case
 \cite{handbook-constraint-programming}. The process of finding these values consists of
\textit{searching} the combinatorial space and either implicitly or explicitly discarding
combinations that cannot be solutions, i.e. does not satisfy the constraints.

\textit{Unison} is a tool that uses a constraint solver to schedule instructions and allocate
registers as a single, integrated problem. It operates as a part of the LLVM backend, and
is thus not a standalone compiler. Unison is potentially optimal in the sense that given
enough time, it can generate the optimal instruction schedule and register allocation.
It finds this solution by searching the combinatorial space in a continuous pursuit for a
solution that is better than the last \cite{unison-docs}.

\section{Problem Statement}

It might feel intuitive to provide software diversity by somehow randomizing a part of an
executable, and in fact many have \cite{survey,librando,binary-stirring}, but this
approach comes with a three key challenges: It is difficult to make guarantees about the
resulting population, proving the correctness of the code transformations is challenging
and there is no fine-grained control of the process.

When generating the executables with a random element in the process you cannot make any
guarantees regarding the resulting population. If you generate two executable you cannot
with certainty tell that they are in fact sufficiently different without verifying it. The
risk of them being equal is most likely very small for just two versions, but what if
10000 different version are generated? Or 1000000? At some point the pigeonhole principle
comes into effect, in which case case it would be better to re-use the already generated
code.

By instead systematically generating different variations those sort of guarantees can be
made. If two equal executables are never generated it follows that they are all pairwise
distinct. It also follows that if the code generator is run to termination, all pairwise
distinct versions are generated. There is also opportunity to define exactly what pairwise
distinct entails. The nature of constraint solving lends itself well to this application.
This is where Unison comes in. In addition to its main purpose Unison has potential for
software diversity purposes.

This thesis aims to be an early exploration of a systematic approach to automated software
diversity using a constraint solver, specifically the Unison tool. It aims to evaluate
both the code generator and the generated code. This leads us to the hypothesis that

\say{Systematically generating diverse executables using a constraint solver is at least
as good as basing the diversification process on randomization.}

\section{Motivation}

As mentioned, it is difficult to prove the correctness of code transformations. Perhaps
the most compelling reason to use a constraint solver for software diversity is that for
a combination to be considered a solution, \textit{all} constraints must be satisfied.
Regardless of what unorthodox approach we want to try out we do not need to consider it's
effect on program functionality, since the constraints that ensure a valid program is
generated must still be satisfied. This property makes implementing new techniques
relatively simple. Modifying code while retaining functionality is no easy task, and this
simplifies it greatly.

With the systematic approach there is full control of what changes between versions, and
how much it changes between versions. Instead of introducing randomness into some part of
the compilation process and more or less hope it generates diverse code with low overhead
the systematic approach offers the possibility of properly reasoning about the process and
steering it specific manners. It also yields a greater control of the quality of the
generated code. Limits can be dynamically set in place so that it does not exceed e.g a
certain number of instructions.

\section{Methodology}

This project is an early exploration of the potential benefits of using a constraint solver
for automated software diversity. Specifically, the research will be carried out by
modifying the Unison tool to support generating multiple outputs. Exactly how these
outputs should differ to generate the most diverse population is outside the scope of this
project. With that said, for the purposes of this thesis the modification of Unison will
include three different options of how the resulting code should differ. Both the modified
code generator as well as the resulting population of each of the three options will be
evaluated. This lends itself well to an experimental approach.

The purpose of the experiment is to evaluate both the code generator and the resulting
code. The evaluation of the code generator will be performed on both quantifiable and
non-quantifiable metrics (such as ease of implementation). The resulting code, which will
be a population of functionally equivalent but differently arranged code, will be evaluated
in a purely quantifiable way.

\section{Ethics and Sustainability}

Developing defenses in the field of software security does not generally offer many
ethical controversies. It is in principle always good to offer defense against ominous
deeds. However, generating multiple executables on each invocation of a compiler would
lead to sustainability impacts.

\textcite{compiler-generated-sw-div} describes the architecture for a solution like this
when deployed on a large scale. It involves an "app store" (e.g a package manager
repository or a smartphone app store) where a user asks for a binary and each user is given
a unique variant. The two options are to either generate a new version when one is asked
for or to generate as many versions as feasible beforehand, storing them somewhere and
simply providing one at user requests. Both of these approaches involves more computation
than just compiling a single binary and providing it to all users. In the latter case a
lot of storage is also involved.

Initially either of these factor might not seems like much but requiring additional
computation and potentially storage that scales linearly with users can become a problem
for popular applications, such as certain web browsers or common software libraries. The
extra computation and storage requires power which is costly not only in monetary terms
but also environmentally. Unfortunately, this is an unavoidable consequence of a large
scale deployment of automated software diversity.

\section{Overview}

This thesis is divided into five chapters. The first chapter provides an overview and
introduction of the project background and goal as well as the research method and ethics
and sustainability issues.

Chapter 2, background, presents software diversity and why it is desirable. Also presented
is how the systematic approach will be taken in the form of Unison and constraint
programming.

Chapter 3 and 4 of the thesis consists of, respectively, what experiment has
been done and the results of that experiment. The last chapter discusses the shortcomings
of the experiment, the future work required and the conclusion.
