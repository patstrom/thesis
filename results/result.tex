\chapter{Results and Discussion}

In this chapter each metric mentioned in Section \ref{sec:metrics} will be presented in
its own section. An interpretation of the result will also be presented for each
metric, but all general discussion will be in chapter \ref{chapter:discussion}.

\section{Generation Time}

\begin{figure}[h]
	\centering
	\includegraphics[width=\textwidth,height=0.5\textheight]{results/figures/generator_time}
	\caption{The execution time of the code generator at sampling rate 1000 (i.e 1000000 solutions for every function). Each marker represents the finished generation of a function. The markers are ordered so that the nth marker on every line represents the same function. Total time is annotated as hours and minutes.}
	\label{fig:time}
\end{figure}

The execution times of the constraint solver at sampling rate 1000 are shown in Figure
\ref{fig:time}. Each marker represents the completed generation of a function. That is,
for each marker 1000000 (one million) solutions have been explored. For a few functions
fewer than 1000 solutions were found (for a complete breakdown see appendix
\ref{appendix:function_names}).

While the total execution time is daunting, it does represent about 23 million solutions
found (but only 23000 emitted). The enumerate strategy is fairly quick: 51 minutes for one
million solutions of every function means that on average, one solution was found every
139ns. The same number for registers and schedule is 343ns and 1095ns respectively. To
mitigate the impact of a long execution time the solutions can be emitted directly when
found.

disUnison does not use the same search heuristics as the base Unison model. The disUnison
search heuristics makes implementation easier at the potential cost of execution time. The
problem with optimizing the branching and search heuristics of the model is that the
performance impact will largely have to be determined empirically. Supposedly, the optimal
search heuristic for the registers strategy would not be the same as the optimal search
heuristic for the schedule strategy.

\section{Cost}
\label{sec:cost_result}

\begin{figure}[h]
	\centering
	\includegraphics[width=\textwidth,height=0.5\textheight]{results/figures/cost_speed}
	\caption{The cost (speed) distributions for every strategy and sampling rate. The cost of the LLVM solution is included for reference.}
	\label{fig:cost-speed}
\end{figure}

\begin{figure}[h]
	\centering
	\includegraphics[width=\textwidth,height=0.5\textheight]{results/figures/cost_size}
	\caption{The code size distributions for every strategy and sampling rate. The cost of the LLVM solution is included for reference.}
	\label{fig:cost-size}
\end{figure}

Figure \ref{fig:cost-speed} and Figure \ref{fig:cost-size} shows the distributions of the
estimated cost in cycles and the code size for each strategy and sampling rate
respectively. Both the cost in cycles and the code size for a program version is
calculated as the geometric mean between the cost of the individual functions that make
up the program version. That is, for every strategy and sampling rate there are 1000
values for each cost metric, where each value is a geometric mean between the cost values
of 23 functions.

All strategies perform better for lower sampling rates both in terms of speed and in terms
of code size. As described in section \ref{sec:sampling_rate}, this is expected. Both the
enumerate and registers strategy performs very well compared to the LLVM solution
in terms of speed. The schedule strategy incurs a slight overhead for the lowest sampling
rate and a significant overhead for the three higher sampling rates.

The fact that no solution has a size lower than the LLVM solution can be explained by
referring to the optimization goal used, which was speed. The code size has not been taken
into account during branching and no attempt has been made to optimize it.

Interesting to note is that all strategies and sampling rates have found a solution with
an equally low speed. This is the very first solution found and it is upon this solution
the first strategy related constraints are based. Thanks to the search heuristic, where
lower cost solutions are explored first, this is also the optimal speed.

\section{Surviving Gadgets}

\begin{figure}[htp]
	\centering
	\includegraphics[width=\textwidth,height=\textheight]{results/figures/gadgets}
	\caption{The ratio of occurrence for each gadget broken down by strategy and sampling rate.
The x-axis displays the gadget ids. The first non-zero x-tick and the second non-zero x-tick
displays the first gadget that only appear in one program version and the total number
of unique gadgets, respectively. The data is sorted from most to least frequent to allow
for a better overview.}
	\label{fig:gadgets}
\end{figure}

Figure \ref{fig:gadgets} shows the occurrence ratio of each gadget for the different
strategies and sampling rates. The x-axis shows a gadget id and there is no definitive
correlation between the gadgets across strategies and sampling rates. The ids are ordered
from most frequent to least frequent to better facilitate comparison. The first non-zero
x-tick refers to the id of the first gadget that only appear once and the second non-zero
x-tick is the total number of unique gadgets. E.g the enumerate strategy at sampling rate
1 has $1561-906=655$ gadgets that only appear in one program version. Strategies and
sampling rates that were more effective have a higher number of unique gadgets. The y-axis
is set to a logarithmic scale since the bulk of the data is below 1\%. The frequency of
the most frequent gadget is annotated.

As seen in Figure \ref{fig:gadgets}, neither the enumeration nor the registers strategy
were particularly effective at breaking gadgets for any sampling rate, when compared to
the schedule strategy. There is a slight improvement for higher sampling rates but it is
not particularly impressive even at sampling rate 1000. There are still many gadgets that
survives across a large percentage of versions. The schedule strategy, however, performed
well with no gadget being present in even 50\% of all versions for the lowest sampling
rate and for sampling rate 1000 about 82\% of gadgets only appear in one version.

If an adversary were to construct a payload for a binary from the schedule strategy
at sampling rate 1000 the chances of it working on another binary in that population is
very small. Even if the payload only relies on a single gadget, and that gadget happens
to be the most frequent one, the payload would only work on about 24\% of the binaries. It
is, however, much more likely that an adversary needs multiple gadgets. Since 82\% of
all gadgets are unique to their program version and the gadgets has to be exactly equal on
for the payload to work on another binary it is very unlikely that the adversary can re-use
the payload at all. Unfortunately the schedule strategy also incurred the most overhead,
as seen in Section \ref{cost_result}.

The difference in behavior of the strategies is discussed in Section \ref{sec:discussion}.
